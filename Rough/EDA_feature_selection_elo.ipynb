{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA_feature_selection_elo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/human-ai2025/Elo-Merchant-Recommendation/blob/master/EDA_feature_selection_elo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSNUHQTd_jbt"
      },
      "source": [
        "#Import Libraries \r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "import gc\r\n",
        "from contextlib import contextmanager\r\n",
        "from pandas.core.common import SettingWithCopyWarning\r\n",
        "import datetime\r\n",
        "import time\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "from scipy.stats import mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0gy8in1_jYK",
        "outputId": "e44ece31-aa20-4ed9-f5f3-de3651a8e076"
      },
      "source": [
        "#Mounting drive \r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feJTkhbC_jVa",
        "outputId": "0bdf0a2b-6660-47f0-b90f-7b6ad923f23f"
      },
      "source": [
        "#Setting up worksapce directory \r\n",
        "%cd /content/drive/MyDrive/data "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxDmUU0b_jSw"
      },
      "source": [
        "#refer:-https://www.youtube.com/watch?v=vOMtQ4ocMGI\r\n",
        "\r\n",
        "@contextmanager\r\n",
        "def timer(title):\r\n",
        "    \"\"\" used to calculate time for each function\"\"\"\r\n",
        "    t0 = time.time()\r\n",
        "    yield\r\n",
        "    print(\"{} - done in {:.000f}s\".format(title, time.time() - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiFE8Io2_jQM"
      },
      "source": [
        "#https://www.kaggle.com/fabiendaniel/elo-world\r\n",
        "#Function to load data into pandas and reduce memory usage\r\n",
        "\r\n",
        "def reduce_mem_usage(df, verbose=True):\r\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\r\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \r\n",
        "    #loop for alll the columns in the dataframe \r\n",
        "    for col in df.columns:\r\n",
        "        #get the datatype of the column\r\n",
        "        col_type = df[col].dtypes\r\n",
        "        #if the data type is numeric then only start changing the datatype\r\n",
        "        #as it isnt much helpful for other data types \r\n",
        "        if col_type in numerics:\r\n",
        "            #stores the min value of the column \r\n",
        "            c_min = df[col].min()\r\n",
        "            #stores the maximum value of the column\r\n",
        "            c_max = df[col].max()\r\n",
        "            #for int type numerics\r\n",
        "            if str(col_type)[:3] == 'int':\r\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\r\n",
        "                    df[col] = df[col].astype(np.int8)\r\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\r\n",
        "                    df[col] = df[col].astype(np.int16)\r\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\r\n",
        "                    df[col] = df[col].astype(np.int32)\r\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\r\n",
        "                    df[col] = df[col].astype(np.int64)  \r\n",
        "            #for float type numerics \r\n",
        "            else:\r\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\r\n",
        "                    df[col] = df[col].astype(np.float16)\r\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\r\n",
        "                    df[col] = df[col].astype(np.float32)\r\n",
        "                else:\r\n",
        "                    df[col] = df[col].astype(np.float64)    \r\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\r\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\r\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjIqob7HAElV"
      },
      "source": [
        "#Refer:-https://stackoverflow.com/questions/36631163/what-are-the-pros-and-cons-between-get-dummies-pandas-and-onehotencoder-sciki\r\n",
        "def one_hot_encoder(df, nan_as_category=True):\r\n",
        "    \"\"\"used to create the one hot encoding of the categorical variables \"\"\"\r\n",
        "    original_columns = list(df.columns)\r\n",
        "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\r\n",
        "    print(\"The columns on which one hot encoding is performed is \",categorical_columns)\r\n",
        "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\r\n",
        "    new_columns = [c for c in df.columns if c not in original_columns]\r\n",
        "    return df, new_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0CcFpbkQwdy"
      },
      "source": [
        "'index', 'authorized_flag', 'card_id', 'city_id', 'category_1',\r\n",
        "       'installments', 'category_3', 'merchant_category_id', 'merchant_id',\r\n",
        "       'month_lag', 'purchase_amount', 'purchase_date', 'category_2',\r\n",
        "       'state_id', 'subsector_id', 'merchant_group_id_merchants_t',\r\n",
        "       'merchant_category_id_merchants_t', 'subsector_id_merchants_t',\r\n",
        "       'numerical_1_merchants_t', 'numerical_2_merchants_t',\r\n",
        "       'category_1_merchants_t', 'most_recent_sales_range_merchants_t',\r\n",
        "       'most_recent_purchases_range_merchants_t', 'avg_sales_lag3_merchants_t',\r\n",
        "       'avg_purchases_lag3_merchants_t', 'active_months_lag3_merchants_t',\r\n",
        "       'avg_sales_lag6_merchants_t', 'avg_purchases_lag6_merchants_t',\r\n",
        "       'active_months_lag6_merchants_t', 'avg_sales_lag12_merchants_t',\r\n",
        "       'avg_purchases_lag12_merchants_t', 'active_months_lag12_merchants_t',\r\n",
        "       'category_4_merchants_t', 'city_id_merchants_t', 'state_id_merchants_t',\r\n",
        "       'category_2_merchants_t']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wnYS-XIB4OT"
      },
      "source": [
        "def ground_on_card_id(df):\r\n",
        "    \"\"\"\r\n",
        "    FUNCTION:\r\n",
        "    To group the data on card id  \r\n",
        "\r\n",
        "    ARGS:\r\n",
        "    df is the data frame on which grouping needs to be performed \r\n",
        "\r\n",
        "    RETURNS:\r\n",
        "    returns the data frame after grouping \r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #Some feature engineering on date and time  \r\n",
        "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\r\n",
        "    df['month'] = df['purchase_date'].dt.month\r\n",
        "    df['day'] = df['purchase_date'].dt.day\r\n",
        "    df['hour'] = df['purchase_date'].dt.hour\r\n",
        "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\r\n",
        "    df['weekday'] = df['purchase_date'].dt.weekday\r\n",
        "    df['weekend'] = (df['purchase_date'].dt.weekday >= 5).astype(int)\r\n",
        "\r\n",
        "    #for id \r\n",
        "    col_id = ['city_id','merchant_id','state_id',\r\n",
        "                            'subsector_id','merchant_group_id_merchants_t','state_id_merchants_t',\r\n",
        "                            'merchant_category_id_merchants_t','subsector_id_merchants_t','city_id_merchants_t']\r\n",
        "    #for numerical \r\n",
        "    col_numerical = ['month_lag', 'purchase_amount', 'month', 'hour', 'weekofyear', 'weekday', 'day',\r\n",
        "                      'numerical_2_merchants_t','avg_sales_lag3_merchants_t',\r\n",
        "                      'avg_purchases_lag3_merchants_t', 'active_months_lag3_merchants_t',\r\n",
        "                      'avg_sales_lag6_merchants_t', 'avg_purchases_lag6_merchants_t',\r\n",
        "                      'active_months_lag6_merchants_t', 'avg_sales_lag12_merchants_t',\r\n",
        "                      'avg_purchases_lag12_merchants_t', 'active_months_lag12_merchants_t']\r\n",
        "\r\n",
        "    aggs = {}\r\n",
        "    for col in col_id:\r\n",
        "        aggs[col] = ['nunique']\r\n",
        "\r\n",
        "    for col in col_numerical:\r\n",
        "        aggs[col] = ['nunique', 'mean', 'min', 'max']\r\n",
        "\r\n",
        "    aggs['purchase_amount'] = ['sum', 'max', 'min', 'mean']\r\n",
        "    aggs['installments'] = ['sum', 'max', 'mean']\r\n",
        "    aggs['purchase_date'] = ['max', 'min']\r\n",
        "    aggs['month_lag'] = ['max', 'min', 'mean']\r\n",
        "    aggs['authorized_flag'] = ['mean']\r\n",
        "    aggs['category_1'] = ['mean']\r\n",
        "    aggs['category_2'] = ['mean']\r\n",
        "    aggs['category_3'] = ['mean']\r\n",
        "    aggs['category_1_merchants_t'] = ['mean']\r\n",
        "    aggs['category_2_merchants_t'] = ['mean']\r\n",
        "    aggs['category_4_merchants_t'] = ['mean']\r\n",
        "    aggs['most_recent_sales_range_merchants_t'] = ['mean']\r\n",
        "    aggs['most_recent_purchases_range_merchants_t'] = ['mean']\r\n",
        "\r\n",
        "    df = df.reset_index().groupby('card_id').agg(aggs)\r\n",
        "\r\n",
        "    # change column name\r\n",
        "    df.columns = pd.Index([e[0] + \"_\" + e[1] for e in df.columns.tolist()])\r\n",
        "    df.columns = ['new_' + c for c in df.columns]\r\n",
        "    \r\n",
        "    # reduce memory usage\r\n",
        "    df = reduce_mem_usage(df)\r\n",
        "\r\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7AajLtzB4K4"
      },
      "source": [
        "def transactions_data_imputations(df):\r\n",
        "    \"\"\"\r\n",
        "    FUNCTION:\r\n",
        "    Tohandle the missing values and inf values \r\n",
        "\r\n",
        "    ARGS:\r\n",
        "    df is the dataframe to be imputed\r\n",
        "\r\n",
        "    RETURNS:\r\n",
        "    returns the data frame after imputations \r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    #for category 1 and authorized flag \r\n",
        "    #as they ahve no null values so directly encoding \r\n",
        "    df['category_1'] = df['category_1'].map({'Y': 0, 'N': 1}).astype(int)\r\n",
        "    df['authorized_flag'] = df['authorized_flag'].map({'Y': 0, 'N': 1}).astype(int)\r\n",
        "\r\n",
        "    #for category 3 \r\n",
        "    #There are three categorical values with missing values \r\n",
        "    df['category_3'] = df['category_3'].fillna(3)\r\n",
        "    df['category_3'] = df['category_3'].map({'A': 0, 'B': 1,'C': 2, 3:3}).astype(int)\r\n",
        "\r\n",
        "    #for category_1_merchants_t_merchants_t\r\n",
        "    # it contains 2 categorical and null values\r\n",
        "    df['category_1_merchants_t'] = df['category_1_merchants_t'].fillna(2)\r\n",
        "    df['category_1_merchants_t'] = df['category_1_merchants_t'].map({'Y': 0, 'N': 1,2:2}).astype(int)\r\n",
        "\r\n",
        "    #for most_recent_sales_range_merchants_t_merchants_t and most_recent_purchases_range_merchants_t_merchants_t\r\n",
        "    #it has A,B,C,D,E and null values \r\n",
        "    df['most_recent_sales_range_merchants_t'] = df['most_recent_sales_range_merchants_t'].fillna(5)\r\n",
        "    df['most_recent_purchases_range_merchants_t'] = df['most_recent_purchases_range_merchants_t'].fillna(5)\r\n",
        "    df['most_recent_sales_range_merchants_t'] = df['most_recent_sales_range_merchants_t'].map({'A': 0, 'B': 1,'C': 2, 'D': 3,'E' : 4, 5 : 5}).astype(int)\r\n",
        "    df['most_recent_purchases_range_merchants_t'] = df['most_recent_purchases_range_merchants_t'].map({'A': 0, 'B': 1,'C': 2, 'D': 3,'E' : 4, 5 : 5}).astype(int)\r\n",
        "    \r\n",
        "    #for category_4_merchants_t_merchants_t\r\n",
        "    #it has Y,N and null values \r\n",
        "    df['category_4_merchants_t'] = df['category_4_merchants_t'].fillna(2)\r\n",
        "    df['category_4_merchants_t'] = df['category_4_merchants_t'].map({'Y': 0, 'N': 1, 2 : 2}).astype(int)\r\n",
        "\r\n",
        "    #for category_2_merchants_t_merchants_t and category_2\r\n",
        "    #it has 1.0,2.0,3.0,4.05.0 and null values \r\n",
        "    df['category_2_merchants_t'] = df['category_2_merchants_t'].fillna(6)\r\n",
        "    df['category_2'] = df['category_2'].fillna(6)\r\n",
        "    df['category_2_merchants_t'] = df['category_2_merchants_t'].map({1.0 : 1, 2.0 : 2, 3.0 : 3,4.0 : 4, 5.0 : 5, 6 : 6}).astype(int)\r\n",
        "    df['category_2'] = df['category_2'].map({1.0 : 1, 2.0 : 2, 3.0 : 3,4.0 : 4, 5.0 : 5, 6 : 6}).astype(int)\r\n",
        "\r\n",
        "    #for missing id we will use -1111 as filling value \r\n",
        "    #find the number of missing values \r\n",
        "    for col in df[['city_id','merchant_id','state_id',\r\n",
        "                            'subsector_id','merchant_group_id_merchants_t','state_id_merchants_t',\r\n",
        "                            'merchant_category_id_merchants_t','subsector_id_merchants_t','city_id_merchants_t']]:\r\n",
        "                            df[col] = df[col].fillna(-1111)\r\n",
        "\r\n",
        "    #imputing the inf values with max \r\n",
        "    features_inf = [\"avg_purchases_lag3_merchants_t\",\"avg_purchases_lag6_merchants_t\",\"avg_purchases_lag12_merchants_t\"]\r\n",
        "    for col in features_inf:\r\n",
        "        df.loc[df[col]==np.inf,col] = max(df.loc[df[col]!=np.inf,col])\r\n",
        "        \r\n",
        "\r\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wU_pf0L_jNi"
      },
      "source": [
        "def merge_trans_merch(num_rows=None):\r\n",
        "    \"\"\"\r\n",
        "    FUNCTION:\r\n",
        "    To merge transactions and merchant return the dataframe\r\n",
        "\r\n",
        "    ARGS:\r\n",
        "    num_rows to indicate the number of rows to load \r\n",
        "\r\n",
        "    RETURNS:\r\n",
        "    returns the merged data frame \r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    historical_transactions = pd.read_csv('historical_transactions.csv', nrows=num_rows)\r\n",
        "    new_merchant_transactions = pd.read_csv('new_merchant_transactions.csv', nrows=num_rows)\r\n",
        "    merchants = pd.read_csv('merchants.csv', nrows=num_rows)\r\n",
        "\r\n",
        "    historical_transactions = reduce_mem_usage(historical_transactions)\r\n",
        "    new_merchant_transactions = reduce_mem_usage(new_merchant_transactions)\r\n",
        "    new_merchant_transactions = reduce_mem_usage(new_merchant_transactions)\r\n",
        "\r\n",
        "\r\n",
        "    #The transactions and new merchat transactions has the same columns  \r\n",
        "    transactions = pd.concat([historical_transactions, new_merchant_transactions], ignore_index=True)\r\n",
        "    assert (transactions.shape[0] == historical_transactions.shape[0]+new_merchant_transactions.shape[0])\r\n",
        "\r\n",
        "    merchants.columns = [col+\"_merchants_t\" if col!=\"merchant_id\" else col for col in merchants.columns]\r\n",
        "    df = pd.merge(transactions, merchants,how=\"left\",on=\"merchant_id\")\r\n",
        "    del new_merchant_transactions\r\n",
        "    del historical_transactions\r\n",
        "    del transactions\r\n",
        "    gc.collect()\r\n",
        "\r\n",
        "    df = reduce_mem_usage(df)\r\n",
        "\r\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXk2cIcgLKdY"
      },
      "source": [
        "def merge_with_train_test(num_rows=None):\r\n",
        "    \"\"\"\r\n",
        "    FUNCTION:\r\n",
        "    To merge transactions and merchant return the dataframe\r\n",
        "\r\n",
        "    ARGS:\r\n",
        "    num_rows to indicate the number of rows to load \r\n",
        "\r\n",
        "    RETURNS:\r\n",
        "    returns the merged data frame \r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    \r\n",
        "\r\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2meStF2x_jK3"
      },
      "source": [
        "def generate_augmented_train_test(num_rows = None):\r\n",
        "    \"\"\" Generate train and test augmented datasets i.e to join different dataframes \"\"\"\r\n",
        "    with timer(\"merge_trans_merch_data\"):\r\n",
        "      df = merge_trans_merch(num_rows).reset_index()\r\n",
        "    with timer(\"imputation\"):\r\n",
        "      df = transactions_data_imputations(df)\r\n",
        "    with timer(\"imputation\"):\r\n",
        "      df = ground_on_card_id(df)\r\n",
        "    return df\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yonYSWj_jIU",
        "outputId": "70bfef00-e8c4-4b76-f8d6-6db9b7b8ce92"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "    df = generate_augmented_train_test(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to  0.00 Mb (41.7% reduction)\n",
            "Mem. usage decreased to  0.00 Mb (41.7% reduction)\n",
            "Mem. usage decreased to  0.00 Mb (0.0% reduction)\n",
            "Mem. usage decreased to  0.00 Mb (0.0% reduction)\n",
            "merge_trans_merch_data - done in 0s\n",
            "imputation - done in 0s\n",
            "Mem. usage decreased to  0.00 Mb (50.1% reduction)\n",
            "imputation - done in 0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "iZ8mbOrQ_jFp",
        "outputId": "5ca5993d-42ca-4d2f-92a4-6a935fb2a67a"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_city_id_nunique</th>\n",
              "      <th>new_merchant_id_nunique</th>\n",
              "      <th>new_state_id_nunique</th>\n",
              "      <th>new_subsector_id_nunique</th>\n",
              "      <th>new_merchant_group_id_merchants_t_nunique</th>\n",
              "      <th>new_state_id_merchants_t_nunique</th>\n",
              "      <th>new_merchant_category_id_merchants_t_nunique</th>\n",
              "      <th>new_subsector_id_merchants_t_nunique</th>\n",
              "      <th>new_city_id_merchants_t_nunique</th>\n",
              "      <th>new_month_lag_max</th>\n",
              "      <th>new_month_lag_min</th>\n",
              "      <th>new_month_lag_mean</th>\n",
              "      <th>new_purchase_amount_sum</th>\n",
              "      <th>new_purchase_amount_max</th>\n",
              "      <th>new_purchase_amount_min</th>\n",
              "      <th>new_purchase_amount_mean</th>\n",
              "      <th>new_month_nunique</th>\n",
              "      <th>new_month_mean</th>\n",
              "      <th>new_month_min</th>\n",
              "      <th>new_month_max</th>\n",
              "      <th>new_hour_nunique</th>\n",
              "      <th>new_hour_mean</th>\n",
              "      <th>new_hour_min</th>\n",
              "      <th>new_hour_max</th>\n",
              "      <th>new_weekofyear_nunique</th>\n",
              "      <th>new_weekofyear_mean</th>\n",
              "      <th>new_weekofyear_min</th>\n",
              "      <th>new_weekofyear_max</th>\n",
              "      <th>new_weekday_nunique</th>\n",
              "      <th>new_weekday_mean</th>\n",
              "      <th>new_weekday_min</th>\n",
              "      <th>new_weekday_max</th>\n",
              "      <th>new_day_nunique</th>\n",
              "      <th>new_day_mean</th>\n",
              "      <th>new_day_min</th>\n",
              "      <th>new_day_max</th>\n",
              "      <th>new_numerical_2_merchants_t_nunique</th>\n",
              "      <th>new_numerical_2_merchants_t_mean</th>\n",
              "      <th>new_numerical_2_merchants_t_min</th>\n",
              "      <th>new_numerical_2_merchants_t_max</th>\n",
              "      <th>...</th>\n",
              "      <th>new_active_months_lag3_merchants_t_min</th>\n",
              "      <th>new_active_months_lag3_merchants_t_max</th>\n",
              "      <th>new_avg_sales_lag6_merchants_t_nunique</th>\n",
              "      <th>new_avg_sales_lag6_merchants_t_mean</th>\n",
              "      <th>new_avg_sales_lag6_merchants_t_min</th>\n",
              "      <th>new_avg_sales_lag6_merchants_t_max</th>\n",
              "      <th>new_avg_purchases_lag6_merchants_t_nunique</th>\n",
              "      <th>new_avg_purchases_lag6_merchants_t_mean</th>\n",
              "      <th>new_avg_purchases_lag6_merchants_t_min</th>\n",
              "      <th>new_avg_purchases_lag6_merchants_t_max</th>\n",
              "      <th>new_active_months_lag6_merchants_t_nunique</th>\n",
              "      <th>new_active_months_lag6_merchants_t_mean</th>\n",
              "      <th>new_active_months_lag6_merchants_t_min</th>\n",
              "      <th>new_active_months_lag6_merchants_t_max</th>\n",
              "      <th>new_avg_sales_lag12_merchants_t_nunique</th>\n",
              "      <th>new_avg_sales_lag12_merchants_t_mean</th>\n",
              "      <th>new_avg_sales_lag12_merchants_t_min</th>\n",
              "      <th>new_avg_sales_lag12_merchants_t_max</th>\n",
              "      <th>new_avg_purchases_lag12_merchants_t_nunique</th>\n",
              "      <th>new_avg_purchases_lag12_merchants_t_mean</th>\n",
              "      <th>new_avg_purchases_lag12_merchants_t_min</th>\n",
              "      <th>new_avg_purchases_lag12_merchants_t_max</th>\n",
              "      <th>new_active_months_lag12_merchants_t_nunique</th>\n",
              "      <th>new_active_months_lag12_merchants_t_mean</th>\n",
              "      <th>new_active_months_lag12_merchants_t_min</th>\n",
              "      <th>new_active_months_lag12_merchants_t_max</th>\n",
              "      <th>new_installments_sum</th>\n",
              "      <th>new_installments_max</th>\n",
              "      <th>new_installments_mean</th>\n",
              "      <th>new_purchase_date_max</th>\n",
              "      <th>new_purchase_date_min</th>\n",
              "      <th>new_authorized_flag_mean</th>\n",
              "      <th>new_category_1_mean</th>\n",
              "      <th>new_category_2_mean</th>\n",
              "      <th>new_category_3_mean</th>\n",
              "      <th>new_category_1_merchants_t_mean</th>\n",
              "      <th>new_category_2_merchants_t_mean</th>\n",
              "      <th>new_category_4_merchants_t_mean</th>\n",
              "      <th>new_most_recent_sales_range_merchants_t_mean</th>\n",
              "      <th>new_most_recent_purchases_range_merchants_t_mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>card_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C_ID_415bb3a509</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.25</td>\n",
              "      <td>-2.349609</td>\n",
              "      <td>-0.551270</td>\n",
              "      <td>-0.671875</td>\n",
              "      <td>-0.587402</td>\n",
              "      <td>2</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>13.75</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>12.25000</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>2.750000</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>15.750000</td>\n",
              "      <td>7</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-04-26 14:08:44</td>\n",
              "      <td>2018-03-07 09:43:21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C_ID_4e6213e9bc</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-11</td>\n",
              "      <td>-7.00</td>\n",
              "      <td>-7.175781</td>\n",
              "      <td>-0.657227</td>\n",
              "      <td>-0.737793</td>\n",
              "      <td>-0.717773</td>\n",
              "      <td>7</td>\n",
              "      <td>5.800781</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>12.50</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>22.90625</td>\n",
              "      <td>8</td>\n",
              "      <td>46</td>\n",
              "      <td>6</td>\n",
              "      <td>3.900391</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>14.101562</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-02-24 08:45:05</td>\n",
              "      <td>2017-03-10 01:14:19</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C_ID_ef55cf8d4b</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.50</td>\n",
              "      <td>2.214844</td>\n",
              "      <td>5.265625</td>\n",
              "      <td>-0.659668</td>\n",
              "      <td>0.369141</td>\n",
              "      <td>2</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>16.00</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>13.00000</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-04-07 18:37:40</td>\n",
              "      <td>2018-03-17 18:10:41</td>\n",
              "      <td>0</td>\n",
              "      <td>0.833496</td>\n",
              "      <td>1.833008</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 new_city_id_nunique  ...  new_most_recent_purchases_range_merchants_t_mean\n",
              "card_id                               ...                                                  \n",
              "C_ID_415bb3a509                    4  ...                                                 5\n",
              "C_ID_4e6213e9bc                    3  ...                                                 5\n",
              "C_ID_ef55cf8d4b                    3  ...                                                 5\n",
              "\n",
              "[3 rows x 90 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dof-oucW_jDH",
        "outputId": "84b6b1b3-06b8-4624-ff45-dd62e2123636"
      },
      "source": [
        "df.isnull().sum(axis = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "new_city_id_nunique                                 0\n",
              "new_merchant_id_nunique                             0\n",
              "new_state_id_nunique                                0\n",
              "new_subsector_id_nunique                            0\n",
              "new_merchant_group_id_merchants_t_nunique           0\n",
              "                                                   ..\n",
              "new_category_1_merchants_t_mean                     0\n",
              "new_category_2_merchants_t_mean                     0\n",
              "new_category_4_merchants_t_mean                     0\n",
              "new_most_recent_sales_range_merchants_t_mean        0\n",
              "new_most_recent_purchases_range_merchants_t_mean    0\n",
              "Length: 90, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8988t32P8Zj"
      },
      "source": [
        "#Gives the name of all the variables with missing data \r\n",
        "\r\n",
        "columns_with_na = [var for var in df.columns if df[var].isnull().mean()  > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVALonFoVZEh",
        "outputId": "a3385487-4695-4913-9335-dc4c59a591bb"
      },
      "source": [
        "len(columns_with_na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "id": "Ye28I_dFU4jP",
        "outputId": "bd2aec0c-4fdc-4bd4-d337-fa0500ee6039"
      },
      "source": [
        "#lets find out the percentage of observations missing per variable\r\n",
        "\r\n",
        "#calculate the percentage of missing \r\n",
        "data_na = df[columns_with_na].isnull().mean()\r\n",
        "\r\n",
        "#transform the array to dataframe \r\n",
        "data_na = pd.DataFrame(data_na.reset_index())\r\n",
        "\r\n",
        "#add names to the dataframe \r\n",
        "data_na.columns = ['col','percentage_na']\r\n",
        "\r\n",
        "#oreder the dataframe acc to percentage \r\n",
        "data_na.sort_values(by = 'percentage_na',ascending = False, inplace = True)\r\n",
        "\r\n",
        "#show\r\n",
        "data_na"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col</th>\n",
              "      <th>percentage_na</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new_numerical_2_merchants_t_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>new_numerical_2_merchants_t_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>new_active_months_lag12_merchants_t_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>new_active_months_lag12_merchants_t_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>new_avg_purchases_lag12_merchants_t_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>new_avg_purchases_lag12_merchants_t_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>new_avg_purchases_lag12_merchants_t_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>new_avg_sales_lag12_merchants_t_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>new_avg_sales_lag12_merchants_t_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>new_avg_sales_lag12_merchants_t_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>new_active_months_lag6_merchants_t_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>new_active_months_lag6_merchants_t_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>new_active_months_lag6_merchants_t_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>new_avg_purchases_lag6_merchants_t_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>new_avg_purchases_lag6_merchants_t_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>new_avg_purchases_lag6_merchants_t_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>new_avg_sales_lag6_merchants_t_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>new_avg_sales_lag6_merchants_t_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>new_avg_sales_lag6_merchants_t_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>new_active_months_lag3_merchants_t_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>new_active_months_lag3_merchants_t_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>new_active_months_lag3_merchants_t_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>new_avg_purchases_lag3_merchants_t_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>new_avg_purchases_lag3_merchants_t_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>new_avg_purchases_lag3_merchants_t_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>new_avg_sales_lag3_merchants_t_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>new_avg_sales_lag3_merchants_t_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>new_avg_sales_lag3_merchants_t_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new_numerical_2_merchants_t_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>new_active_months_lag12_merchants_t_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         col  percentage_na\n",
              "0           new_numerical_2_merchants_t_mean            1.0\n",
              "1            new_numerical_2_merchants_t_min            1.0\n",
              "28   new_active_months_lag12_merchants_t_min            1.0\n",
              "27  new_active_months_lag12_merchants_t_mean            1.0\n",
              "26   new_avg_purchases_lag12_merchants_t_max            1.0\n",
              "25   new_avg_purchases_lag12_merchants_t_min            1.0\n",
              "24  new_avg_purchases_lag12_merchants_t_mean            1.0\n",
              "23       new_avg_sales_lag12_merchants_t_max            1.0\n",
              "22       new_avg_sales_lag12_merchants_t_min            1.0\n",
              "21      new_avg_sales_lag12_merchants_t_mean            1.0\n",
              "20    new_active_months_lag6_merchants_t_max            1.0\n",
              "19    new_active_months_lag6_merchants_t_min            1.0\n",
              "18   new_active_months_lag6_merchants_t_mean            1.0\n",
              "17    new_avg_purchases_lag6_merchants_t_max            1.0\n",
              "16    new_avg_purchases_lag6_merchants_t_min            1.0\n",
              "15   new_avg_purchases_lag6_merchants_t_mean            1.0\n",
              "14        new_avg_sales_lag6_merchants_t_max            1.0\n",
              "13        new_avg_sales_lag6_merchants_t_min            1.0\n",
              "12       new_avg_sales_lag6_merchants_t_mean            1.0\n",
              "11    new_active_months_lag3_merchants_t_max            1.0\n",
              "10    new_active_months_lag3_merchants_t_min            1.0\n",
              "9    new_active_months_lag3_merchants_t_mean            1.0\n",
              "8     new_avg_purchases_lag3_merchants_t_max            1.0\n",
              "7     new_avg_purchases_lag3_merchants_t_min            1.0\n",
              "6    new_avg_purchases_lag3_merchants_t_mean            1.0\n",
              "5         new_avg_sales_lag3_merchants_t_max            1.0\n",
              "4         new_avg_sales_lag3_merchants_t_min            1.0\n",
              "3        new_avg_sales_lag3_merchants_t_mean            1.0\n",
              "2            new_numerical_2_merchants_t_max            1.0\n",
              "29   new_active_months_lag12_merchants_t_max            1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUVQY2uhU4fz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1oPwfvpU4dy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_836G4GU4b3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btzzu_DqU4Zz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUEyiuqx_jA4"
      },
      "source": [
        "with timer(\"transactions_data_imputations_data\"):\r\n",
        "      df = transactions_data_imputations()\r\n",
        "        \r\n",
        "    with timer(\"split train & test\"):\r\n",
        "        train_df = df[df['target'].notnull()]\r\n",
        "        test_df = df[df['target'].isnull()]\r\n",
        "        del test_df['target']\r\n",
        "        del df\r\n",
        "        gc.collect()\r\n",
        "    with timer(\"Save train and test files\"):\r\n",
        "        train_df.to_csv('/content/drive/MyDrive/data/augmented_train.csv', index=False)\r\n",
        "        test_df.to_csv('/content/drive/MyDrive/data/augmented_test.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqgn_lZI_i-Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_jprP5__i7x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Soc2wayg_i5P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4LOW01H_i2z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1kCJF5F_i0C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjkvhP3C_ixe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRJfgDlD_ivQ"
      },
      "source": [
        "def lgb_train_fn(train_df, target, trn_cols,  n_fold):\r\n",
        "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=4590)\r\n",
        "    # initialise out of fold preds to 0s.\r\n",
        "    oof = np.zeros(len(train_df))\r\n",
        "\r\n",
        "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df,train_df['outliers'].values)):\r\n",
        "        trn_data = lgb.Dataset(train_df.iloc[trn_idx][trn_cols], label=target.iloc[trn_idx])\r\n",
        "        val_data = lgb.Dataset(train_df.iloc[val_idx][trn_cols], label=target.iloc[val_idx])\r\n",
        "\r\n",
        "        num_round = 10000\r\n",
        "        clf = lgb.train(lgb_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=0, early_stopping_rounds = 200)\r\n",
        "        oof[val_idx] = clf.predict(train_df.iloc[val_idx][trn_cols], num_iteration=clf.best_iteration)\r\n",
        "\r\n",
        "    print(np.sqrt(mean_squared_error(oof, target)), 'CV score')\r\n",
        "    return np.sqrt(mean_squared_error(oof, target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViM9-tMEPYhR"
      },
      "source": [
        "for c in cols_to_add:\r\n",
        "    lgb_cols = final_cols + [c]\r\n",
        "    print(len(lgb_cols), 'lg_cols', c)\r\n",
        "    score = lgb_train_fn(x, y, lgb_cols, 5)\r\n",
        "    delta = base_score - score\r\n",
        "    fe_d[c] = delta\r\n",
        "    if delta > 0:\r\n",
        "        base_score = score\r\n",
        "        selected_cols.append(c)\r\n",
        "        print('Selected cols', c)\r\n",
        "        print('Selected col delta', delta)\r\n",
        "        print(' score with col', score)\r\n",
        "        np.save('selecte_cols_extra', selected_cols)\r\n",
        "        final_cols = final_cols + [c]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}