{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_merging_data_elo_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/human-ai2025/Elo-Merchant-Recommendation/blob/master/2_merging_data_elo_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSNUHQTd_jbt"
      },
      "source": [
        "#Import Libraries \r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "import gc\r\n",
        "from contextlib import contextmanager\r\n",
        "from pandas.core.common import SettingWithCopyWarning\r\n",
        "import datetime\r\n",
        "import time\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "from scipy.stats import mode"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0gy8in1_jYK",
        "outputId": "daff9810-11cd-4cd6-86c0-ad1bfc4f85d4"
      },
      "source": [
        "#Mounting drive \r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feJTkhbC_jVa",
        "outputId": "0cab5271-37cf-41f6-aacb-356c1d9fd1ad"
      },
      "source": [
        "#Setting up worksapce directory \r\n",
        "%cd /content/drive/MyDrive/data "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxDmUU0b_jSw"
      },
      "source": [
        "#refer:-https://www.youtube.com/watch?v=vOMtQ4ocMGI\r\n",
        "\r\n",
        "@contextmanager\r\n",
        "def timer(title):\r\n",
        "    \"\"\" used to calculate time for each function\"\"\"\r\n",
        "    t0 = time.time()\r\n",
        "    yield\r\n",
        "    print(\"{} - done in {:.000f}s\".format(title, time.time() - t0))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiFE8Io2_jQM"
      },
      "source": [
        "#https://www.kaggle.com/fabiendaniel/elo-world\r\n",
        "#Function to load data into pandas and reduce memory usage\r\n",
        "\r\n",
        "def reduce_mem_usage(df, verbose=True):\r\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\r\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \r\n",
        "    #loop for alll the columns in the dataframe \r\n",
        "    for col in df.columns:\r\n",
        "        #get the datatype of the column\r\n",
        "        col_type = df[col].dtypes\r\n",
        "        #if the data type is numeric then only start changing the datatype\r\n",
        "        #as it isnt much helpful for other data types \r\n",
        "        if col_type in numerics:\r\n",
        "            #stores the min value of the column \r\n",
        "            c_min = df[col].min()\r\n",
        "            #stores the maximum value of the column\r\n",
        "            c_max = df[col].max()\r\n",
        "            #for int type numerics\r\n",
        "            if str(col_type)[:3] == 'int':\r\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\r\n",
        "                    df[col] = df[col].astype(np.int8)\r\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\r\n",
        "                    df[col] = df[col].astype(np.int16)\r\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\r\n",
        "                    df[col] = df[col].astype(np.int32)\r\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\r\n",
        "                    df[col] = df[col].astype(np.int64)  \r\n",
        "            #for float type numerics \r\n",
        "            else:\r\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\r\n",
        "                    df[col] = df[col].astype(np.float16)\r\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\r\n",
        "                    df[col] = df[col].astype(np.float32)\r\n",
        "                else:\r\n",
        "                    df[col] = df[col].astype(np.float64)    \r\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\r\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\r\n",
        "    return df"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjIqob7HAElV"
      },
      "source": [
        "#Refer:-https://stackoverflow.com/questions/36631163/what-are-the-pros-and-cons-between-get-dummies-pandas-and-onehotencoder-sciki\r\n",
        "def one_hot_encoder(df, nan_as_category=True):\r\n",
        "    \"\"\"used to create the one hot encoding of the categorical variables \"\"\"\r\n",
        "    original_columns = list(df.columns)\r\n",
        "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\r\n",
        "    print(\"The columns on which one hot encoding is performed is \",categorical_columns)\r\n",
        "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\r\n",
        "    new_columns = [c for c in df.columns if c not in original_columns]\r\n",
        "    return df, new_columns"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nub7opBCTFbH"
      },
      "source": [
        "def train_test(num_rows=None):\r\n",
        "\r\n",
        "    # load csv\r\n",
        "    train_df = pd.read_csv('/content/drive/MyDrive/data/train.csv', index_col=['card_id'], nrows=num_rows)\r\n",
        "    test_df = pd.read_csv('/content/drive/MyDrive/data/test.csv', index_col=['card_id'], nrows=num_rows)\r\n",
        "\r\n",
        "    print(\"Train samples: {}, test samples: {}\".format(len(train_df), len(test_df)))\r\n",
        "    OUTLIER_THRESHOLD = 30\r\n",
        "    # Create an outliers column set to 1 for\r\n",
        "    train_df['outliers'] = np.where(train_df['target'] < OUTLIER_THRESHOLD, 1, 0)\r\n",
        "\r\n",
        "    # set target as nan\r\n",
        "    test_df['target'] = np.nan\r\n",
        "\r\n",
        "    # merge\r\n",
        "    df = train_df.append(test_df)\r\n",
        "\r\n",
        "    del train_df, test_df\r\n",
        "    gc.collect()\r\n",
        "\r\n",
        "    # to datetime\r\n",
        "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\r\n",
        "\r\n",
        "    # datetime features\r\n",
        "    df['quarter'] = df['first_active_month'].dt.quarter\r\n",
        "    df['elapsed_time'] = (datetime.datetime.today() - df['first_active_month']).dt.days\r\n",
        "    df['quarter_first_active_month'] = df['first_active_month'].dt.quarter\r\n",
        "    df['first_active_month_diff_from_today'] = (datetime.datetime.today() - df['first_active_month']).dt.days\r\n",
        "\r\n",
        "\r\n",
        "    # one hot encoding\r\n",
        "    df, cols = one_hot_encoder(df, nan_as_category=False)\r\n",
        "\r\n",
        "    for col in ['feature_1', 'feature_2', 'feature_3']:\r\n",
        "        order_label = df.groupby(col)['outliers'].mean()\r\n",
        "        df[col] = df[col].map(order_label)\r\n",
        "\r\n",
        "    # Some basic statistics transformations over the feature_i columns\r\n",
        "    df['feature_sum'] = df['feature_1'] + df['feature_2'] + df['feature_3']\r\n",
        "    df['feature_mean'] = df['feature_sum'] / 3\r\n",
        "    df['feature_max'] = df[['feature_1', 'feature_2', 'feature_3']].max(axis=1)\r\n",
        "    df['feature_min'] = df[['feature_1', 'feature_2', 'feature_3']].min(axis=1)\r\n",
        "    df['feature_std'] = df[['feature_1', 'feature_2', 'feature_3']].std(axis=1)\r\n",
        "\r\n",
        "    return df"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zBpC472TFVT"
      },
      "source": [
        "def transactions_imputations(df):\r\n",
        "\r\n",
        "    # fillna\r\n",
        "    df['category_2'].fillna(6, inplace=True)\r\n",
        "    df['category_3'].fillna(3, inplace=True)\r\n",
        "    df['merchant_id'].fillna('M_ID_00a6ca8a8a', inplace=True)\r\n",
        "    df['installments'].replace(-1, np.nan, inplace=True)\r\n",
        "    df['installments'].replace(999, np.nan, inplace=True)\r\n",
        "    df['installments'].fillna(df['installments'].mode()[0], inplace=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    # mapping categorical to numerical \r\n",
        "    df['authorized_flag'] = df['authorized_flag'].map({'Y': 1, 'N': 0}).astype(int)\r\n",
        "    df['category_1'] = df['category_1'].map({'Y': 1, 'N': 0}).astype(int)\r\n",
        "    df['category_3'] = df['category_3'].map({'A': 0, 'B': 1,'C': 2, 3:3}).astype(int)\r\n",
        "    df['category_2'] = df['category_2'].map({1.0 : 1, 2.0 : 2, 3.0 : 3,4.0 : 4, 5.0 : 5, 6 : 6}).astype(int)\r\n",
        "    #removing purchase amount outliner    \r\n",
        "    df['purchase_amount'] = df['purchase_amount'].apply(lambda x: min(x, 0.8))\r\n",
        "    df['price'] = df['purchase_amount'] / (df['installments'] + 0.001) #some epsilone for 0  installments \r\n",
        "\r\n",
        "    # reduce memory usage\r\n",
        "    #df = reduce_mem_usage(df)\r\n",
        "\r\n",
        "    return df\r\n"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOveUvGDZ-7y"
      },
      "source": [
        "def merchant_imputations(num_rows=None):\r\n",
        "    # load csv\r\n",
        "    df = pd.read_csv('/content/drive/MyDrive/data/merchants.csv', nrows=num_rows)\r\n",
        "\r\n",
        "    #drop duplicate merchant id\r\n",
        "    df.drop_duplicates(subset=['merchant_id'], keep='last')\r\n",
        "\r\n",
        "    df['category_1'] = df['category_1'].fillna(2)\r\n",
        "    df['category_1'] = df['category_1'].map({'Y': 0, 'N': 1,2:2}).astype(int)\r\n",
        "\r\n",
        "    #for most_recent_sales_range_merchants_t_merchants_t and most_recent_purchases_range_merchants_t_merchants_t\r\n",
        "    #it has A,B,C,D,E and null values \r\n",
        "    df['most_recent_sales_range'] = df['most_recent_sales_range'].fillna(5)\r\n",
        "    df['most_recent_purchases_range'] = df['most_recent_purchases_range'].fillna(5)\r\n",
        "    df['most_recent_sales_range'] = df['most_recent_sales_range'].map({'A': 0, 'B': 1,'C': 2, 'D': 3,'E' : 4, 5 : 5}).astype(int)\r\n",
        "    df['most_recent_purchases_range'] = df['most_recent_purchases_range'].map({'A': 0, 'B': 1,'C': 2, 'D': 3,'E' : 4, 5 : 5}).astype(int)\r\n",
        "    \r\n",
        "\r\n",
        "    #for category_4_merchants_t_merchants_t\r\n",
        "    #it has Y,N and null values \r\n",
        "    df['category_4'] = df['category_4'].fillna(2)\r\n",
        "    df['category_4'] = df['category_4'].map({'Y': 0, 'N': 1, 2 : 2}).astype(int)\r\n",
        "\r\n",
        "    df['category_2'] = df['category_2'].fillna(6)\r\n",
        "    df['category_2'] = df['category_2'].map({1.0 : 1, 2.0 : 2, 3.0 : 3,4.0 : 4, 5.0 : 5, 6 : 6}).astype(int)\r\n",
        "\r\n",
        "    #for missing id we will use -1111 as filling value \r\n",
        "    #find the number of missing values \r\n",
        "    for col in df[['merchant_group_id','state_id',\r\n",
        "                            'merchant_category_id','subsector_id','city_id']]:\r\n",
        "                            df[col] = df[col].fillna(-1111)\r\n",
        "\r\n",
        "    #imputing the inf values with max \r\n",
        "    features_inf = [\"avg_purchases_lag3\",\"avg_purchases_lag6\",\"avg_purchases_lag12\"]\r\n",
        "    for col in features_inf:\r\n",
        "        df.loc[df[col]==np.inf,col] = max(df.loc[df[col]!=np.inf,col])\r\n",
        "\r\n",
        "    df.columns = [col+\"_merchants_t\" if col!=\"merchant_id\" else col for col in df.columns]\r\n",
        "\r\n",
        "    # reduce memory usage\r\n",
        "    df = reduce_mem_usage(df)\r\n",
        "\r\n",
        "    return df"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jGUahIrmE3W"
      },
      "source": [
        "def group_on_card_id_with_mer(df):\r\n",
        "    \"\"\"\r\n",
        "    FUNCTION:\r\n",
        "    To group the data on card id  \r\n",
        "\r\n",
        "    ARGS:\r\n",
        "    df is the data frame on which grouping needs to be performed \r\n",
        "\r\n",
        "    RETURNS:\r\n",
        "    returns the data frame after grouping \r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #Some feature engineering on date and time  \r\n",
        "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\r\n",
        "    df['month'] = df['purchase_date'].dt.month\r\n",
        "    df['day'] = df['purchase_date'].dt.day\r\n",
        "    df['hour'] = df['purchase_date'].dt.hour\r\n",
        "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\r\n",
        "    df['weekday'] = df['purchase_date'].dt.weekday\r\n",
        "    df['weekend'] = (df['purchase_date'].dt.weekday >= 5).astype(int)\r\n",
        "\r\n",
        "    #for id \r\n",
        "    col_id = ['city_id','merchant_id','state_id',\r\n",
        "                            'subsector_id','merchant_group_id_merchants_t','state_id_merchants_t',\r\n",
        "                            'merchant_category_id_merchants_t','subsector_id_merchants_t','city_id_merchants_t']\r\n",
        "    #for numerical \r\n",
        "    col_numerical = ['month_lag', 'purchase_amount', 'month', 'hour', 'weekofyear', 'weekday', 'day',\r\n",
        "                      'numerical_2_merchants_t','avg_sales_lag3_merchants_t',\r\n",
        "                      'avg_purchases_lag3_merchants_t', 'active_months_lag3_merchants_t',\r\n",
        "                      'avg_sales_lag6_merchants_t', 'avg_purchases_lag6_merchants_t',\r\n",
        "                      'active_months_lag6_merchants_t', 'avg_sales_lag12_merchants_t',\r\n",
        "                      'avg_purchases_lag12_merchants_t', 'active_months_lag12_merchants_t']\r\n",
        "\r\n",
        "    aggs = {}\r\n",
        "    for col in col_id:\r\n",
        "        aggs[col] = ['nunique']\r\n",
        "\r\n",
        "    for col in col_numerical:\r\n",
        "        aggs[col] = ['nunique', 'mean', 'min', 'max']\r\n",
        "\r\n",
        "    aggs['purchase_amount'] = ['sum', 'max', 'min', 'mean']\r\n",
        "    aggs['installments'] = ['sum', 'max', 'mean']\r\n",
        "    aggs['purchase_date'] = ['max', 'min']\r\n",
        "    aggs['month_lag'] = ['max', 'min', 'mean']\r\n",
        "    aggs['authorized_flag'] = ['mean']\r\n",
        "    aggs['category_1'] = ['mean']\r\n",
        "    aggs['category_2'] = ['mean']\r\n",
        "    aggs['category_3'] = ['mean']\r\n",
        "    aggs['category_1_merchants_t'] = ['mean']\r\n",
        "    aggs['category_2_merchants_t'] = ['mean']\r\n",
        "    aggs['category_4_merchants_t'] = ['mean']\r\n",
        "    aggs['most_recent_sales_range_merchants_t'] = ['mean']\r\n",
        "    aggs['most_recent_purchases_range_merchants_t'] = ['mean']\r\n",
        "\r\n",
        "    df = df.reset_index().groupby('card_id').agg(aggs)\r\n",
        "\r\n",
        "    # change column name\r\n",
        "    df.columns = pd.Index([e[0] + \"_\" + e[1] for e in df.columns.tolist()])\r\n",
        "    df.columns = ['new_' + c for c in df.columns]\r\n",
        "    \r\n",
        "    # reduce memory usage\r\n",
        "    df = reduce_mem_usage(df)\r\n",
        "\r\n",
        "    return df"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhL6b3fmqGio"
      },
      "source": [
        "def group_on_card_id(df):\r\n",
        "    \"\"\"\r\n",
        "    FUNCTION:\r\n",
        "    To group the data on card id  \r\n",
        "\r\n",
        "    ARGS: \r\n",
        "    df is the data frame on which grouping needs to be performed \r\n",
        "\r\n",
        "    RETURNS:\r\n",
        "    returns the data frame after grouping \r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #Some feature engineering on date and time  \r\n",
        "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\r\n",
        "    df['month'] = df['purchase_date'].dt.month\r\n",
        "    df['day'] = df['purchase_date'].dt.day\r\n",
        "    df['hour'] = df['purchase_date'].dt.hour\r\n",
        "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\r\n",
        "    df['weekday'] = df['purchase_date'].dt.weekday\r\n",
        "    df['weekend'] = (df['purchase_date'].dt.weekday >= 5).astype(int)\r\n",
        "\r\n",
        "    mode = lambda x: x.value_counts().index[0]\r\n",
        "    range2 = lambda x: np.nanmax(x)-np.nanmin(x)\r\n",
        "\r\n",
        "    date_range = lambda x: (x.max()-x.min())/np.timedelta64(1,'D')\r\n",
        "    days_to_next_purchase_mean = lambda x: np.mean([(np.sort(x)[i+1]-np.sort(x)[i])/np.timedelta64(1,'D') \\\r\n",
        "                                                    for i in range(x.shape[0]-1)])\r\n",
        "    days_to_next_purchase_std = lambda x: np.std([(np.sort(x)[i+1]-np.sort(x)[i])/np.timedelta64(1,'D') \\\r\n",
        "                                                  for i in range(x.shape[0]-1)])\r\n",
        "\r\n",
        "    agg_fun = {\"authorized_flag\": ['sum', 'mean',mode],\r\n",
        "    'category_1' : ['sum', 'mean',mode],\r\n",
        "    'category_2' :['sum', 'mean',mode],\r\n",
        "    'category_3' :['sum', 'mean',mode],\r\n",
        "    'city_id' : ['nunique',mode],\r\n",
        "    'state_id' : ['nunique',mode],\r\n",
        "    'subsector_id' : ['nunique',mode],\r\n",
        "    'merchant_category_id' : ['nunique',mode],\r\n",
        "    'merchant_id': ['nunique',mode],\r\n",
        "    'month_lag' : ['sum', 'mean', 'min', 'max', 'std','var'],\r\n",
        "    'installments' : ['sum', 'mean', 'min', 'max', 'std','var'],\r\n",
        "    'purchase_amount' : ['sum', 'mean', 'min', 'max', 'std','var'],\r\n",
        "    'price': ['sum', 'mean', 'min', 'max', 'var', 'skew'],\r\n",
        "\r\n",
        "    'weekend': ['sum', 'mean'],\r\n",
        "    'weekday' : ['nunique', 'sum', 'mean'],\r\n",
        "    'hour': ['nunique', 'mean', 'min', 'max'],\r\n",
        "    'weekofyear': ['nunique', 'mean', 'min', 'max'],\r\n",
        "    'day': ['nunique', 'sum', 'min'],\r\n",
        "    #Refer:-https://numpy.org/doc/stable/reference/generated/numpy.ptp.html\r\n",
        "    'purchase_date' : [np.ptp, 'min', 'max'],\r\n",
        "    'month' : ['sum', 'mean', 'nunique']\r\n",
        "    }\r\n",
        "    df = df.groupby(\"card_id\",as_index=False).agg(agg_fun)\r\n",
        "\r\n",
        "\r\n",
        "    # change column name\r\n",
        "    df.columns = pd.Index([e[0] + \"_\" + e[1]  for e in df.columns.tolist()])\r\n",
        "    df.columns = ['df_' + c for c in df.columns]\r\n",
        "    \r\n",
        "    # reduce memory usage\r\n",
        "    #df = reduce_mem_usage(df)\r\n",
        "  \r\n",
        "\r\n",
        "    return df"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN7jxp-_JOeu"
      },
      "source": [
        "def generate_augmented_train_test_1(debug=False):\r\n",
        "    \"\"\" Generate train and test augmented datasets. \"\"\"\r\n",
        "    num_rows = 100 if debug else None\r\n",
        "    with timer(\"train & test\"):\r\n",
        "        df = train_test(num_rows).reset_index()\r\n",
        "    with timer(\"transactions\"):\r\n",
        "        # load csv\r\n",
        "        new_merchant_df = pd.read_csv('/content/drive/MyDrive/data/new_merchant_transactions.csv', nrows=num_rows)\r\n",
        "        historical_transactions_df = pd.read_csv('/content/drive/MyDrive/data/historical_transactions.csv', nrows=num_rows)\r\n",
        "        df_1 = pd.concat([historical_transactions_df, new_merchant_df], ignore_index=True)\r\n",
        "        df_1 = transactions_imputations(df_1)\r\n",
        "        df = pd.merge(df, df_1, right_on='card_id',left_on='df_card_id_', how='left')\r\n",
        "        del new_merchant_df\r\n",
        "        del historical_transactions_df\r\n",
        "        gc.collect()\r\n",
        "\r\n",
        "    with timer(\"split train & test\"):\r\n",
        "        train_df = df[df['target'].notnull()]\r\n",
        "        test_df = df[df['target'].isnull()]\r\n",
        "        del test_df['target']\r\n",
        "        del df\r\n",
        "        gc.collect()\r\n",
        "    with timer(\"Save train and test files\"):\r\n",
        "\r\n",
        "        train_df.to_csv('/content/drive/MyDrive/data/augmented_train.csv', index=False)\r\n",
        "        test_df.to_csv('/content/drive/MyDrive/data/augmented_test.csv', index=False)"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljbF5QxSTFEC"
      },
      "source": [
        "def generate_augmented_train_test(debug=False):\r\n",
        "    \"\"\" Generate train and test augmented datasets. \"\"\"\r\n",
        "    num_rows = 100 if debug else None\r\n",
        "    with timer(\"transactions\"):\r\n",
        "        # load csv\r\n",
        "        new_merchant_df = pd.read_csv('/content/drive/MyDrive/data/new_merchant_transactions.csv', nrows=num_rows)\r\n",
        "        historical_transactions_df = pd.read_csv('/content/drive/MyDrive/data/historical_transactions.csv', nrows=num_rows)\r\n",
        "        df = pd.concat([historical_transactions_df, new_merchant_df], ignore_index=True)\r\n",
        "        del new_merchant_df\r\n",
        "        del historical_transactions_df\r\n",
        "        df = transactions_imputations(df)\r\n",
        "        gc.collect()\r\n",
        "    #with timer(\"merchants\"):\r\n",
        "    #    merchants_df = merchant_imputations(num_rows).reset_index()\r\n",
        "    #    print(merchants_df.columns)\r\n",
        "    #    print(df.columns)\r\n",
        "    #    df = pd.merge(df, merchants_df, on='merchant_id', how='left')\r\n",
        "    with timer(\"group_on_card_id\"):\r\n",
        "        df = group_on_card_id(df)\r\n",
        "    with timer(\"train & test\"):\r\n",
        "        tt = train_test(num_rows).reset_index()\r\n",
        "        print(tt.columns)\r\n",
        "        print(df.columns)\r\n",
        "        print(df.isnull().sum(axis = 0))\r\n",
        "        df = pd.merge(df, tt, right_on='card_id',left_on='df_card_id_', how='right')\r\n",
        "    with timer(\"split train & test\"):\r\n",
        "        train_df = df[df['target'].notnull()]\r\n",
        "        test_df = df[df['target'].isnull()]\r\n",
        "        del test_df['target']\r\n",
        "        del df\r\n",
        "        gc.collect()\r\n",
        "    with timer(\"Save train and test files\"):\r\n",
        "        train_df.to_csv('/content/drive/MyDrive/data/augmented_train.csv', index=False)\r\n",
        "        test_df.to_csv('/content/drive/MyDrive/data/augmented_test.csv', index=False)\r\n"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yonYSWj_jIU",
        "outputId": "74895c88-36a8-4d0d-d188-6c38b1f02ec1"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "  generate_augmented_train_test(True)"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "transactions - done in 0s\n",
            "group_on_card_id - done in 0s\n",
            "Train samples: 100, test samples: 100\n",
            "The columns on which one hot encoding is performed is  []\n",
            "Index(['card_id', 'first_active_month', 'feature_1', 'feature_2', 'feature_3',\n",
            "       'target', 'outliers', 'quarter', 'elapsed_time', 'feature_sum',\n",
            "       'feature_mean', 'feature_max', 'feature_min', 'feature_std'],\n",
            "      dtype='object')\n",
            "Index(['df_card_id_', 'df_authorized_flag_sum', 'df_authorized_flag_mean',\n",
            "       'df_authorized_flag_<lambda_0>', 'df_category_1_sum',\n",
            "       'df_category_1_mean', 'df_category_1_<lambda_0>', 'df_category_2_sum',\n",
            "       'df_category_2_mean', 'df_category_2_<lambda_0>', 'df_category_3_sum',\n",
            "       'df_category_3_mean', 'df_category_3_<lambda_0>', 'df_city_id_nunique',\n",
            "       'df_city_id_<lambda_0>', 'df_state_id_nunique',\n",
            "       'df_state_id_<lambda_0>', 'df_subsector_id_nunique',\n",
            "       'df_subsector_id_<lambda_0>', 'df_merchant_category_id_nunique',\n",
            "       'df_merchant_category_id_<lambda_0>', 'df_merchant_id_nunique',\n",
            "       'df_merchant_id_<lambda_0>', 'df_month_lag_sum', 'df_month_lag_mean',\n",
            "       'df_month_lag_min', 'df_month_lag_max', 'df_month_lag_std',\n",
            "       'df_month_lag_var', 'df_installments_sum', 'df_installments_mean',\n",
            "       'df_installments_min', 'df_installments_max', 'df_installments_std',\n",
            "       'df_installments_var', 'df_purchase_amount_sum',\n",
            "       'df_purchase_amount_mean', 'df_purchase_amount_min',\n",
            "       'df_purchase_amount_max', 'df_purchase_amount_std',\n",
            "       'df_purchase_amount_var', 'df_price_sum', 'df_price_mean',\n",
            "       'df_price_min', 'df_price_max', 'df_price_var', 'df_price_skew',\n",
            "       'df_weekend_sum', 'df_weekend_mean', 'df_weekday_nunique',\n",
            "       'df_weekday_sum', 'df_weekday_mean', 'df_hour_nunique', 'df_hour_mean',\n",
            "       'df_hour_min', 'df_hour_max', 'df_weekofyear_nunique',\n",
            "       'df_weekofyear_mean', 'df_weekofyear_min', 'df_weekofyear_max',\n",
            "       'df_day_nunique', 'df_day_sum', 'df_day_min', 'df_purchase_date_ptp',\n",
            "       'df_purchase_date_min', 'df_purchase_date_max', 'df_month_sum',\n",
            "       'df_month_mean', 'df_month_nunique'],\n",
            "      dtype='object')\n",
            "df_card_id_                      0\n",
            "df_authorized_flag_sum           0\n",
            "df_authorized_flag_mean          0\n",
            "df_authorized_flag_<lambda_0>    0\n",
            "df_category_1_sum                0\n",
            "                                ..\n",
            "df_purchase_date_min             0\n",
            "df_purchase_date_max             0\n",
            "df_month_sum                     0\n",
            "df_month_mean                    0\n",
            "df_month_nunique                 0\n",
            "Length: 69, dtype: int64\n",
            "train & test - done in 0s\n",
            "split train & test - done in 0s\n",
            "Save train and test files - done in 0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ8mbOrQ_jFp"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/data/augmented_train.csv', nrows=200)"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dof-oucW_jDH",
        "outputId": "53b77c91-753b-4706-c609-288508e2e624"
      },
      "source": [
        "train_df.isnull().sum(axis = 0)"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "df_card_id_                      100\n",
              "df_authorized_flag_sum           100\n",
              "df_authorized_flag_mean          100\n",
              "df_authorized_flag_<lambda_0>    100\n",
              "df_category_1_sum                100\n",
              "                                ... \n",
              "feature_sum                        0\n",
              "feature_mean                       0\n",
              "feature_max                        0\n",
              "feature_min                        0\n",
              "feature_std                        0\n",
              "Length: 83, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "9Yketas4UlZv",
        "outputId": "b903e967-4f59-47fe-ee45-b9eb04aef8ea"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>df_card_id_</th>\n",
              "      <th>df_authorized_flag_sum</th>\n",
              "      <th>df_authorized_flag_mean</th>\n",
              "      <th>df_authorized_flag_&lt;lambda_0&gt;</th>\n",
              "      <th>df_category_1_sum</th>\n",
              "      <th>df_category_1_mean</th>\n",
              "      <th>df_category_1_&lt;lambda_0&gt;</th>\n",
              "      <th>df_category_2_sum</th>\n",
              "      <th>df_category_2_mean</th>\n",
              "      <th>df_category_2_&lt;lambda_0&gt;</th>\n",
              "      <th>df_category_3_sum</th>\n",
              "      <th>df_category_3_mean</th>\n",
              "      <th>df_category_3_&lt;lambda_0&gt;</th>\n",
              "      <th>df_city_id_nunique</th>\n",
              "      <th>df_city_id_&lt;lambda_0&gt;</th>\n",
              "      <th>df_state_id_nunique</th>\n",
              "      <th>df_state_id_&lt;lambda_0&gt;</th>\n",
              "      <th>df_subsector_id_nunique</th>\n",
              "      <th>df_subsector_id_&lt;lambda_0&gt;</th>\n",
              "      <th>df_merchant_category_id_nunique</th>\n",
              "      <th>df_merchant_category_id_&lt;lambda_0&gt;</th>\n",
              "      <th>df_merchant_id_nunique</th>\n",
              "      <th>df_merchant_id_&lt;lambda_0&gt;</th>\n",
              "      <th>df_month_lag_sum</th>\n",
              "      <th>df_month_lag_mean</th>\n",
              "      <th>df_month_lag_min</th>\n",
              "      <th>df_month_lag_max</th>\n",
              "      <th>df_month_lag_std</th>\n",
              "      <th>df_month_lag_var</th>\n",
              "      <th>df_installments_sum</th>\n",
              "      <th>df_installments_mean</th>\n",
              "      <th>df_installments_min</th>\n",
              "      <th>df_installments_max</th>\n",
              "      <th>df_installments_std</th>\n",
              "      <th>df_installments_var</th>\n",
              "      <th>df_purchase_amount_sum</th>\n",
              "      <th>df_purchase_amount_mean</th>\n",
              "      <th>df_purchase_amount_min</th>\n",
              "      <th>df_purchase_amount_max</th>\n",
              "      <th>df_purchase_amount_std</th>\n",
              "      <th>...</th>\n",
              "      <th>df_price_min</th>\n",
              "      <th>df_price_max</th>\n",
              "      <th>df_price_var</th>\n",
              "      <th>df_price_skew</th>\n",
              "      <th>df_weekend_sum</th>\n",
              "      <th>df_weekend_mean</th>\n",
              "      <th>df_weekday_nunique</th>\n",
              "      <th>df_weekday_sum</th>\n",
              "      <th>df_weekday_mean</th>\n",
              "      <th>df_hour_nunique</th>\n",
              "      <th>df_hour_mean</th>\n",
              "      <th>df_hour_min</th>\n",
              "      <th>df_hour_max</th>\n",
              "      <th>df_weekofyear_nunique</th>\n",
              "      <th>df_weekofyear_mean</th>\n",
              "      <th>df_weekofyear_min</th>\n",
              "      <th>df_weekofyear_max</th>\n",
              "      <th>df_day_nunique</th>\n",
              "      <th>df_day_sum</th>\n",
              "      <th>df_day_min</th>\n",
              "      <th>df_purchase_date_ptp</th>\n",
              "      <th>df_purchase_date_min</th>\n",
              "      <th>df_purchase_date_max</th>\n",
              "      <th>df_month_sum</th>\n",
              "      <th>df_month_mean</th>\n",
              "      <th>df_month_nunique</th>\n",
              "      <th>card_id</th>\n",
              "      <th>first_active_month</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>target</th>\n",
              "      <th>outliers</th>\n",
              "      <th>quarter</th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>feature_sum</th>\n",
              "      <th>feature_mean</th>\n",
              "      <th>feature_max</th>\n",
              "      <th>feature_min</th>\n",
              "      <th>feature_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C_ID_92a2005557</td>\n",
              "      <td>2017-06-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.820283</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1291</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C_ID_3d0044924f</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.392913</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1442</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C_ID_d639edf6cd</td>\n",
              "      <td>2016-08-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.688056</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1595</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C_ID_186d6a6901</td>\n",
              "      <td>2017-09-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.142495</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1199</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C_ID_cdbd2c0db2</td>\n",
              "      <td>2017-11-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.159749</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1138</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C_ID_d9388844f8</td>\n",
              "      <td>2016-08-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.693928</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1595</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C_ID_24b7e16c4f</td>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-2.788379</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1442</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C_ID_a8ad576b32</td>\n",
              "      <td>2017-03-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-2.939943</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1383</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C_ID_26364d47bb</td>\n",
              "      <td>2014-08-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-5.288426</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2326</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C_ID_26655f11a1</td>\n",
              "      <td>2016-09-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.018383</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1564</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  83 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    df_card_id_  df_authorized_flag_sum  ...  feature_min  feature_std\n",
              "0           NaN                     NaN  ...          1.0          0.0\n",
              "1           NaN                     NaN  ...          1.0          0.0\n",
              "2           NaN                     NaN  ...          1.0          0.0\n",
              "3           NaN                     NaN  ...          1.0          0.0\n",
              "4           NaN                     NaN  ...          1.0          0.0\n",
              "..          ...                     ...  ...          ...          ...\n",
              "95          NaN                     NaN  ...          1.0          0.0\n",
              "96          NaN                     NaN  ...          1.0          0.0\n",
              "97          NaN                     NaN  ...          1.0          0.0\n",
              "98          NaN                     NaN  ...          1.0          0.0\n",
              "99          NaN                     NaN  ...          1.0          0.0\n",
              "\n",
              "[100 rows x 83 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8988t32P8Zj"
      },
      "source": [
        "#Gives the name of all the variables with missing data \r\n",
        "\r\n",
        "columns_with_na = [var for var in train_df.columns if train_df[var].isnull().mean()  > 0]"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVALonFoVZEh",
        "outputId": "bb28df17-1357-4914-b446-3b16e0c6238b"
      },
      "source": [
        "len(columns_with_na)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "Ye28I_dFU4jP",
        "outputId": "67708907-4523-42c3-ce72-adab66461f98"
      },
      "source": [
        "#lets find out the percentage of observations missing per variable\r\n",
        "\r\n",
        "#calculate the percentage of missing \r\n",
        "data_na = train_df[columns_with_na].isnull().mean()\r\n",
        "\r\n",
        "#transform the array to dataframe \r\n",
        "data_na = pd.DataFrame(data_na.reset_index())\r\n",
        "\r\n",
        "#add names to the dataframe \r\n",
        "data_na.columns = ['col','percentage_na']\r\n",
        "\r\n",
        "#oreder the dataframe acc to percentage \r\n",
        "data_na.sort_values(by = 'percentage_na',ascending = False, inplace = True)\r\n",
        "\r\n",
        "#show\r\n",
        "data_na"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col</th>\n",
              "      <th>percentage_na</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>df_card_id_</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>df_price_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>df_weekday_sum</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>df_weekday_nunique</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>df_weekend_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>df_installments_sum</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>df_installments_mean</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>df_installments_min</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>df_installments_max</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>df_month_nunique</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     col  percentage_na\n",
              "0            df_card_id_            1.0\n",
              "44          df_price_max            1.0\n",
              "50        df_weekday_sum            1.0\n",
              "49    df_weekday_nunique            1.0\n",
              "48       df_weekend_mean            1.0\n",
              "..                   ...            ...\n",
              "29   df_installments_sum            1.0\n",
              "30  df_installments_mean            1.0\n",
              "31   df_installments_min            1.0\n",
              "32   df_installments_max            1.0\n",
              "68      df_month_nunique            1.0\n",
              "\n",
              "[69 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqgn_lZI_i-Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_jprP5__i7x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Soc2wayg_i5P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4LOW01H_i2z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1kCJF5F_i0C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjkvhP3C_ixe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRJfgDlD_ivQ"
      },
      "source": [
        "def lgb_train_fn(train_df, target, trn_cols,  n_fold):\r\n",
        "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=4590)\r\n",
        "    # initialise out of fold preds to 0s.\r\n",
        "    oof = np.zeros(len(train_df))\r\n",
        "\r\n",
        "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df,train_df['outliers'].values)):\r\n",
        "        trn_data = lgb.Dataset(train_df.iloc[trn_idx][trn_cols], label=target.iloc[trn_idx])\r\n",
        "        val_data = lgb.Dataset(train_df.iloc[val_idx][trn_cols], label=target.iloc[val_idx])\r\n",
        "\r\n",
        "        num_round = 10000\r\n",
        "        clf = lgb.train(lgb_param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=0, early_stopping_rounds = 200)\r\n",
        "        oof[val_idx] = clf.predict(train_df.iloc[val_idx][trn_cols], num_iteration=clf.best_iteration)\r\n",
        "\r\n",
        "    print(np.sqrt(mean_squared_error(oof, target)), 'CV score')\r\n",
        "    return np.sqrt(mean_squared_error(oof, target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViM9-tMEPYhR"
      },
      "source": [
        "for c in cols_to_add:\r\n",
        "    lgb_cols = final_cols + [c]\r\n",
        "    print(len(lgb_cols), 'lg_cols', c)\r\n",
        "    score = lgb_train_fn(x, y, lgb_cols, 5)\r\n",
        "    delta = base_score - score\r\n",
        "    fe_d[c] = delta\r\n",
        "    if delta > 0:\r\n",
        "        base_score = score\r\n",
        "        selected_cols.append(c)\r\n",
        "        print('Selected cols', c)\r\n",
        "        print('Selected col delta', delta)\r\n",
        "        print(' score with col', score)\r\n",
        "        np.save('selecte_cols_extra', selected_cols)\r\n",
        "        final_cols = final_cols + [c]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}